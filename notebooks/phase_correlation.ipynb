{"cells":[{"cell_type":"markdown","metadata":{"id":"mnE4ddMg7Hpa"},"source":["# Phase Correlation"]},{"cell_type":"markdown","metadata":{"id":"bZyqHC9p7XvN"},"source":["Necessary libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"My2-tWWy7WG9"},"outputs":[],"source":["#phase correlation libraries\n","import numpy as np\n","from scipy import misc\n","from argparse import ArgumentParser\n","\n","#complementary labraries\n","from google.colab import drive\n","import sys\n","import os\n","import matplotlib.pyplot as plt\n","import cv2\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"hhGruJCO7yIj"},"source":["Mounting my repository"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22904,"status":"ok","timestamp":1685885146971,"user":{"displayName":"Lucas Meyer","userId":"01190894692144934680"},"user_tz":180},"id":"t8i0BZTC7utx","outputId":"03c469e1-6230-440d-ce0e-ad2c90904ce5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive', force_remount=True)\n","\n","sys.path.append('/content/drive/My Drive/repo/codes/')\n","from utils import video_utils"]},{"cell_type":"markdown","metadata":{"id":"zeDfU3U2gSxl"},"source":["Necessary functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r0QLkPo3gC4Y"},"outputs":[],"source":["def scale_img(src, scale):\n","    # calculate new dimensions\n","    new_w = int(src.shape[1] * scale)\n","    new_h = int(src.shape[0] * scale)\n","\n","    return cv2.resize(src, (new_w, new_h))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aE3qNrhtgDRf"},"outputs":[],"source":["def phase_correlation(img, img_offset, scale=None):\n","    \"\"\"Image translation registration by cross-correlation.\n","    It obtains an estimate of the cross-correlation peak by an FFT.\n","    It is very similar to `skimage.feature.register_translation`.\n","    However, our function runs faster because we restrict it to our application.\n","    Args:\n","        img (array): image.\n","        img_offset (array): offset image. Must have the same dim as `img`.\n","        scale (float, optional): If not `None`, rescale input images to run faster.\n","        Defaults to None.\n","    Returns:\n","        array:  shift vector (in pixels) required to register `img_offset` with\n","        `img`.  Axis ordering is consistent with numpy (e.g. Z, Y, X)\n","    \"\"\"\n","\n","    if img.shape != img_offset.shape:\n","        raise ValueError(\"Error: images must be same size\")\n","\n","    # if images in BGR, tranform to grayscal and use fft2\n","    # which is much faster than using fftn\n","    # if img.ndim > 2:\n","    #     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    # if img_offset.ndim > 2:\n","    #     img_offset = cv2.cvtColor(img_offset, cv2.COLOR_BGR2GRAY)\n","\n","    img = np.float32(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n","    img_offset = np.float32(cv2.cvtColor(img_offset, cv2.COLOR_BGR2GRAY))\n","\n","    if scale is not None:\n","        img = scale_img(img, scale)\n","        img_offset = scale_img(img_offset, scale)\n","\n","    (x, y), c = cv2.phaseCorrelate(img, img_offset)\n","\n","    # img_fft = np.fft.fft2(img)\n","    # img_offset_fft = np.fft.fft2(img_offset)\n","\n","    # shape = img_fft.shape\n","    # midpoints = np.array([np.fix(axis_size / 2) for axis_size in shape])\n","\n","    # R = img_fft * img_offset_fft.conj()\n","    # # R /= np.absolute(R)  # normalize give wrong results for large frames interval (???)\n","    # # (print('norm'))\n","    # cross_correlation = np.fft.ifft2(R)\n","\n","    # shifts = np.unravel_index(np.argmax(np.absolute(cross_correlation)), shape)\n","    # shifts = np.array(shifts, dtype=np.float64)\n","    # shifts[shifts > midpoints] -= np.array(shape)[shifts > midpoints]\n","\n","    if scale is not None:\n","        x /= scale\n","        y /= scale\n","\n","    return (x, y), c"]},{"cell_type":"markdown","metadata":{"id":"e11mumcE8Z6v"},"source":["Generating video object"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPkqXBfM8Imn"},"outputs":[],"source":["video_path = '/content/drive/My Drive/repo/Excidio Mosquitoes/Dataset/2019-06-01_tubiacanga'\n","video_name = 'DJI_0006.MOV'\n","video = os.path.join(video_path, video_name)\n","totalFrames = video_utils.videoObj(videopath=video).videoInfo.getNumberOfFrames()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EmE_Pg4Ty64k","executionInfo":{"status":"ok","timestamp":1685885996216,"user_tz":180,"elapsed":823827,"user":{"displayName":"Lucas Meyer","userId":"01190894692144934680"}},"outputId":"a5017d1b-e52d-48b2-c7ce-e94281c2de2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["7856\n"]}],"source":["counter = 0\n","r_array = []\n","x = []\n","y = []\n","c = []\n","video_capture = cv2.VideoCapture(video)\n","aux = video_capture.read()\n","while counter < totalFrames - 2:\n","  frameA = aux\n","  frameB = video_capture.read()\n","  aux = frameB\n","  results = phase_correlation(frameA[1], frameB[1], scale = 0.4)\n","  r_array.append(results)\n","  x.append(results[0][0])\n","  y.append(results[0][1])\n","  c.append(results[1])\n","  counter += 1\n","print(len(r_array))"]},{"cell_type":"markdown","source":["# Datagram"],"metadata":{"id":"zYEF6tn_MzlE"}},{"cell_type":"code","source":["x_dataframe = pd.DataFrame(x)\n","x_dataframe.columns = ['x']\n","y_dataframe = pd.DataFrame(y)\n","y_dataframe.columns = ['y']\n","c_dataframe = pd.DataFrame(c)\n","c_dataframe.columns = ['c']\n","r_dataframe = pd.concat([x_dataframe, y_dataframe,c_dataframe], axis=1)"],"metadata":{"id":"Hw9Q_ZsrMkkD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["r_dataframe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"J9W5IWEfpMMt","executionInfo":{"status":"ok","timestamp":1685886131279,"user_tz":180,"elapsed":7,"user":{"displayName":"Lucas Meyer","userId":"01190894692144934680"}},"outputId":"f811aee1-9089-4474-d86d-8a3e7a69514e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             x          y         c\n","0     0.407954  27.894525  0.642195\n","1     0.345023  27.727847  0.650097\n","2     0.215085  27.822124  0.647268\n","3     0.552312  27.916742  0.655054\n","4     0.426195  28.050108  0.661009\n","...        ...        ...       ...\n","7851  0.121545  23.795570  0.811877\n","7852  0.101397  23.531686  0.858672\n","7853 -0.137545  23.103048  0.888666\n","7854  0.036892  22.745888  0.912389\n","7855  0.250999  21.187103  0.867580\n","\n","[7856 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-be8a4050-311b-40a5-ae94-b078ef0f077f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>c</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.407954</td>\n","      <td>27.894525</td>\n","      <td>0.642195</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.345023</td>\n","      <td>27.727847</td>\n","      <td>0.650097</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.215085</td>\n","      <td>27.822124</td>\n","      <td>0.647268</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.552312</td>\n","      <td>27.916742</td>\n","      <td>0.655054</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.426195</td>\n","      <td>28.050108</td>\n","      <td>0.661009</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7851</th>\n","      <td>0.121545</td>\n","      <td>23.795570</td>\n","      <td>0.811877</td>\n","    </tr>\n","    <tr>\n","      <th>7852</th>\n","      <td>0.101397</td>\n","      <td>23.531686</td>\n","      <td>0.858672</td>\n","    </tr>\n","    <tr>\n","      <th>7853</th>\n","      <td>-0.137545</td>\n","      <td>23.103048</td>\n","      <td>0.888666</td>\n","    </tr>\n","    <tr>\n","      <th>7854</th>\n","      <td>0.036892</td>\n","      <td>22.745888</td>\n","      <td>0.912389</td>\n","    </tr>\n","    <tr>\n","      <th>7855</th>\n","      <td>0.250999</td>\n","      <td>21.187103</td>\n","      <td>0.867580</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7856 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be8a4050-311b-40a5-ae94-b078ef0f077f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-be8a4050-311b-40a5-ae94-b078ef0f077f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-be8a4050-311b-40a5-ae94-b078ef0f077f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["r_dataframe.to_csv('phase_correlation.csv', index=False)"],"metadata":{"id":"bA9GqNA_pcK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cat phase_correlation.csv"],"metadata":{"id":"hvEOc8nhp_SZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp phase_correlation.csv '/content/drive/My Drive/repo/phase_correlation.csv'"],"metadata":{"id":"Wdhn4kbDqitm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IVU03G4La3QE"},"source":["## Notes"]},{"cell_type":"markdown","metadata":{"id":"gwobSedFcZmF"},"source":["Eu quero que as imagens consigam mais ou menos se correlacionar em 20% de borda. Sabe? Então tipo assim.\n","Eu quero fazer a correlação do primeiro frame com o segundo.\n","Se forem imagens muito parecidas o pico da correlação tem que ser próximo de zero (Imagens quase não são defasadas)\n","\n","Conforme a defasagem das imagens for aumentando, o pico vai apresentar uma crescente linear. Quando o shift entrar na tolerância de borda de imagem que quero, significa que os frames corrrespondem a frames consecutivos da separação."]},{"cell_type":"markdown","metadata":{"id":"rVt-JojceGDI"},"source":["Tomar cuidado com o vetor de direção do drone. Nas bordas, haverá uma alteração na direção desse vetor, ao detectar essa alteração haverá muita distinção entre as imagens caso não tenha chegado na margem estabelecida entre frames consecutivos."]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMDQVO956vQN9y2gD3xcxXS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}