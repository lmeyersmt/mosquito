{"cells":[{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":836,"status":"ok","timestamp":1692684475839,"user":{"displayName":"Lucas Meyer","userId":"01190894692144934680"},"user_tz":180},"id":"EXfGnkfRYCQB"},"outputs":[],"source":["import os\n","import sys\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from PIL import Image"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17223,"status":"ok","timestamp":1692684493058,"user":{"displayName":"Lucas Meyer","userId":"01190894692144934680"},"user_tz":180},"id":"04MYbfwiLtJr","outputId":"75725fd4-cede-43ab-d797-0622c81c5697"},"outputs":[],"source":["sys.path.append('../../codes')\n","from utils import video_utils"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":674,"status":"ok","timestamp":1692684493727,"user":{"displayName":"Lucas Meyer","userId":"01190894692144934680"},"user_tz":180},"id":"gfeFoBQ1fkbV","outputId":"fc947d29-28e7-41a4-85a9-ad695ae6563f"},"outputs":[{"name":"stderr","output_type":"stream","text":["J� existe uma subpasta ou um arquivo ../../Regioes/tubiacanga.\n","J� existe uma subpasta ou um arquivo ../../Regioes/tubiacanga/frames.\n","J� existe uma subpasta ou um arquivo ../../Regioes/tubiacanga/frames/all.\n"]},{"name":"stderr","output_type":"stream","text":["J� existe uma subpasta ou um arquivo ../../Regioes/tubiacanga/frames/overlaped.\n","J� existe uma subpasta ou um arquivo ../../Regioes/tubiacanga/dataFrames.\n","J� existe uma subpasta ou um arquivo ../../Regioes/tubiacanga/dataFrames/all.\n","J� existe uma subpasta ou um arquivo ../../Regioes/tubiacanga/dataFrames/overlaped.\n"]}],"source":["!mkdir \"../../Regioes/tubiacanga\"\n","!mkdir \"../../Regioes/tubiacanga/frames\"\n","!mkdir \"../../Regioes/tubiacanga/frames/all\"\n","!mkdir \"../../Regioes/tubiacanga/frames/overlaped\"\n","!mkdir \"../../Regioes/tubiacanga/dataFrames\"\n","!mkdir \"../../Regioes/tubiacanga/dataFrames/all\"\n","!mkdir \"../../Regioes/tubiacanga/dataFrames/overlaped\"\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["ALL_FRAMES_STRING = 'tubiacanga/frames/all/'\n","OVERLAPED = '../../Regioes/tubiacanga/dataFrames/overlaped/'"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692684493727,"user":{"displayName":"Lucas Meyer","userId":"01190894692144934680"},"user_tz":180},"id":"ALjyezaLLteA"},"outputs":[],"source":["VIDEO_PATH = '../../Dataset/videos/tubiacanga/'\n","VIDEO_NAMES = ['20190601_rectfied_DJI_0002.avi','20190601_rectfied_DJI_0003.avi']\n"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1692684493728,"user":{"displayName":"Lucas Meyer","userId":"01190894692144934680"},"user_tz":180},"id":"g9GzewHDEyXY"},"outputs":[],"source":["videos = []\n","logs = []\n","for i in VIDEO_NAMES:\n","  videos.append(VIDEO_PATH + i)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["['../../Dataset/videos/tubiacanga/20190601_rectfied_DJI_0002.avi',\n"," '../../Dataset/videos/tubiacanga/20190601_rectfied_DJI_0003.avi']"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["videos"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":4434,"status":"ok","timestamp":1692684498157,"user":{"displayName":"Lucas Meyer","userId":"01190894692144934680"},"user_tz":180},"id":"Y2gQRrzYfn2z"},"outputs":[],"source":["videos_obj = []\n","videos_capture = []\n","for i in videos:\n","  videos_capture.append(cv2.VideoCapture(i))"]},{"cell_type":"markdown","metadata":{},"source":["## Logging phase_correlation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["frames_count = 0\n","for path in os.listdir(all_path):\n","  if os.path.isfile(os.path.join(all_path, path)):\n","    frames_count += 1\n","r_array = []\n","x = []\n","y = []\n","c = []\n","counter = 1\n","frameB = cv2.imread(all_path + 'frame_{}.jpeg'.format('{:05d}').format(counter))\n","while counter < frames_count:\n","  counter += 1\n","  frameA = frameB\n","  frameB = cv2.imread(all_path + 'frame_{}.jpeg'.format('{:05d}').format(counter))\n","  results = phase_correlation(frameA, frameB, scale = 0.4)\n","  r_array.append(results)\n","  x.append(results[0][0])\n","  y.append(results[0][1])\n","  c.append(results[1])\n","print (len(r_array))\n","x_dataFrame = pd.DataFrame(x)\n","x_dataFrame.columns = ['x']\n","y_dataFrame = pd.DataFrame(y)\n","y_dataFrame.columns = ['y']\n","c_dataFrame = pd.DataFrame(c)\n","c_dataFrame.columns = ['c']\n","r_dataFrame = pd.concat([x_dataFrame, y_dataFrame, c_dataFrame], axis=1)\n","return r_dataFrame"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["def phase_correlation(img, img_offset, scale=None):\n","    \"\"\"Image translation registration by cross-correlation.\n","    It obtains an estimate of the cross-correlation peak by an FFT.\n","    It is very similar to `skimage.feature.register_translation`.\n","    However, our function runs faster because we restrict it to our application.\n","    Args:\n","        img (array): image.\n","        img_offset (array): offset image. Must have the same dim as `img`.\n","        scale (float, optional): If not `None`, rescale input images to run faster.\n","        Defaults to None.\n","    Returns:\n","        array:  shift vector (in pixels) required to register `img_offset` with\n","        `img`.  Axis ordering is consistent with numpy (e.g. Z, Y, X)\n","    \"\"\"\n","\n","    if img.shape != img_offset.shape:\n","        raise ValueError(\"Error: images must be same size\")\n","\n","    # if images in BGR, tranform to grayscal and use fft2\n","    # which is much faster than using fftn\n","    # if img.ndim > 2:\n","    #     img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    # if img_offset.ndim > 2:\n","    #     img_offset = cv2.cvtColor(img_offset, cv2.COLOR_BGR2GRAY)\n","\n","    img = np.float32(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n","    img_offset = np.float32(cv2.cvtColor(img_offset, cv2.COLOR_BGR2GRAY))\n","\n","    if scale is not None:\n","        img = scale_img(img, scale)\n","        img_offset = scale_img(img_offset, scale)\n","\n","    (x, y), c = cv2.phaseCorrelate(img, img_offset)\n","\n","    # img_fft = np.fft.fft2(img)\n","    # img_offset_fft = np.fft.fft2(img_offset)\n","\n","    # shape = img_fft.shape\n","    # midpoints = np.array([np.fix(axis_size / 2) for axis_size in shape])\n","\n","    # R = img_fft * img_offset_fft.conj()\n","    # # R /= np.absolute(R)  # normalize give wrong results for large frames interval (???)\n","    # # (print('norm'))\n","    # cross_correlation = np.fft.ifft2(R)\n","\n","    # shifts = np.unravel_index(np.argmax(np.absolute(cross_correlation)), shape)\n","    # shifts = np.array(shifts, dtype=np.float64)\n","    # shifts[shifts > midpoints] -= np.array(shape)[shifts > midpoints]\n","\n","    if scale is not None:\n","        x /= scale\n","        y /= scale\n","\n","    return (x, y), c"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[33], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m frameA \u001b[39m=\u001b[39m frameB\n\u001b[0;32m     11\u001b[0m frameB \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39mread()\n\u001b[1;32m---> 12\u001b[0m results \u001b[39m=\u001b[39m phase_correlation(frameA[\u001b[39m1\u001b[39;49m], frameB[\u001b[39m1\u001b[39;49m])\n\u001b[0;32m     13\u001b[0m r_array\u001b[39m.\u001b[39mappend(results)\n\u001b[0;32m     14\u001b[0m x\u001b[39m.\u001b[39mappend(results[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n","Cell \u001b[1;32mIn[32], line 33\u001b[0m, in \u001b[0;36mphase_correlation\u001b[1;34m(img, img_offset, scale)\u001b[0m\n\u001b[0;32m     30\u001b[0m     img \u001b[39m=\u001b[39m scale_img(img, scale)\n\u001b[0;32m     31\u001b[0m     img_offset \u001b[39m=\u001b[39m scale_img(img_offset, scale)\n\u001b[1;32m---> 33\u001b[0m (x, y), c \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mphaseCorrelate(img, img_offset)\n\u001b[0;32m     35\u001b[0m \u001b[39m# img_fft = np.fft.fft2(img)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39m# img_offset_fft = np.fft.fft2(img_offset)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m# shifts = np.array(shifts, dtype=np.float64)\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39m# shifts[shifts > midpoints] -= np.array(shape)[shifts > midpoints]\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39mif\u001b[39;00m scale \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["r_array = []\n","x = []\n","y = []\n","c = []\n","counter = 0\n","for i in videos_capture:\n","    frameB = i.read()\n","    while frameB[0]:\n","        counter += 1\n","        frameA = frameB\n","        frameB = i.read()\n","        results = phase_correlation(frameA[1], frameB[1], 0.4)\n","        r_array.append(results)\n","        x.append(results[0][0])\n","        y.append(results[0][1])\n","        c.append(results[1])\n","print(frameA)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Esquecido por falta de memória e velocidade"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1692684498158,"user":{"displayName":"Lucas Meyer","userId":"01190894692144934680"},"user_tz":180},"id":"KFDL5wuLWDOx"},"outputs":[],"source":["counter = 0\n","total_frames = []\n","for i in videos_obj:\n","  total_frames.append(i.videoInfo.getNumberOfFrames())\n","for i in range(len(videos_capture)):\n","  aux_counter = 0\n","  while aux_counter < total_frames[i]:\n","    counter = counter + 1\n","    aux_counter = aux_counter + 1\n","    frame = videos_capture[i].read()\n","    image = Image.fromarray(cv2.cvtColor(frame[1],cv2.COLOR_BGR2RGB))\n","    string = ALL_FRAMES_STRING + 'frame_{}.jpeg'.format('{:05d}'.format(counter))\n","    image.save(string,'JPEG')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOKkWcFiLxzyXJWPYTGBZZR","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
